{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f72e6-bd23-45d0-89b6-e4a6de39d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "imagePath = 'input_image.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b2e14b-2b28-41a8-8a85-0a130b249fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagePath) # imread from the opencv library(cv2) will convert an image to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f48bf-5386-47f3-a1b8-552addf81060",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape # format: height, width, channels(BGR) - standard for cv2 library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93833d31-e47f-41d9-b9fa-35a27d552921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One step that can improve computational effeciency is to convert an image to a grayscale before performing face detection\n",
    "gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82476844-991a-4628-87d8-be3099713dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3664603-d8f9-4c7b-b9fa-82442a87f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pre-trained Haar Cascade Classifier\n",
    "# haarcascade_frontalface_default.xml is designed specifically for frontal face detection\n",
    "face_classifier = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b29e1-d83e-466e-84b5-06d8207dc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detectMultiScale is used to identiy faces of different sizes in the image\n",
    "face = face_classifier.detectMultiScale(\n",
    "    gray_image,\n",
    "    scaleFactor = 1.1, # Shrinks the image by 10% to improve performance\n",
    "    minNeighbors = 5, # The higher the minNeighbors the less false positives but the more missed faces and vise versa\n",
    "    minSize = (40, 40) # smallest size of the object that can be detected\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e1a17-bff6-4905-8eec-8aa8625533e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing a box\n",
    "for (x, y, w, h) in face:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "# last two parameters: param 1--color of box, param 2--thickness of box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbec848-1d19-4602-992c-78667734bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the image back to a BGR format\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f91e7-d7fd-4726-b063-6db0c0061f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d6d91b-4c60-4c53-9290-5e8f83bedc46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
